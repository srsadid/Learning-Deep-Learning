{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # reading , filtering the old csv , sorting the images according to the level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observing the data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique lebels : [0, 1]\n",
      "unique patient ids: 26684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>c1edf42b-5958-47ff-a1e7-4f23d99583ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>c1f6b555-2eb1-4231-98f6-50a963976431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>233.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30227 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "0      0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN   \n",
       "1      00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN   \n",
       "2      00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN   \n",
       "3      003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN   \n",
       "4      00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0   \n",
       "...                                     ...    ...    ...    ...     ...   \n",
       "30222  c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8  185.0  298.0  228.0   379.0   \n",
       "30223  c1edf42b-5958-47ff-a1e7-4f23d99583ba    NaN    NaN    NaN     NaN   \n",
       "30224  c1f6b555-2eb1-4231-98f6-50a963976431    NaN    NaN    NaN     NaN   \n",
       "30225  c1f7889a-9ea9-4acb-b64c-b737c929599a  570.0  393.0  261.0   345.0   \n",
       "30226  c1f7889a-9ea9-4acb-b64c-b737c929599a  233.0  424.0  201.0   356.0   \n",
       "\n",
       "       Target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "30222       1  \n",
       "30223       0  \n",
       "30224       0  \n",
       "30225       1  \n",
       "30226       1  \n",
       "\n",
       "[30227 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##importing the csv lebel file \n",
    "df = pd.read_csv(r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\rsna-pneumonia-detection-challenge\\stage_2_train_labels.csv')\n",
    "#print (df)\n",
    "\n",
    "\n",
    "## finds unique levels and creates folders\n",
    "Target = list(df['Target'].unique())\n",
    "print (f'unique lebels : {Target}') \n",
    "\n",
    "patientId = list(df['patientId'].unique())\n",
    "print (f'unique patient ids: {len(patientId)}') \n",
    "\n",
    "\n",
    "## make directories \n",
    "#for w in Target:\n",
    "  #os.makedirs(r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\data/'+ str(w))\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.46.1-py2.py3-none-any.whl (63 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.46.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering and removing the data in the csv that does not correspond to any images in the training folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##importing the csv lebel file \n",
    "df = pd.read_csv(r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\rsna-pneumonia-detection-challenge\\stage_2_train_labels.csv')\n",
    "\n",
    "## another case is finding duplicate number of patient ids and removing them from the data frame\n",
    "df1 = df.drop_duplicates(subset =\"patientId\", keep = 'first' ) \n",
    "\n",
    "df1.to_csv (r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\updated_train_lebel.csv', index = False, header=True)\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the new modified data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26679</th>\n",
       "      <td>c1e73a4e-7afe-4ec5-8af6-ce8315d7a2f2</td>\n",
       "      <td>666.0</td>\n",
       "      <td>418.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26680</th>\n",
       "      <td>c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8</td>\n",
       "      <td>609.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26681</th>\n",
       "      <td>c1edf42b-5958-47ff-a1e7-4f23d99583ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26682</th>\n",
       "      <td>c1f6b555-2eb1-4231-98f6-50a963976431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26683</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26684 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "0      0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN   \n",
       "1      00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN   \n",
       "2      00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN   \n",
       "3      003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN   \n",
       "4      00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0   \n",
       "...                                     ...    ...    ...    ...     ...   \n",
       "26679  c1e73a4e-7afe-4ec5-8af6-ce8315d7a2f2  666.0  418.0  186.0   223.0   \n",
       "26680  c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8  609.0  464.0  240.0   284.0   \n",
       "26681  c1edf42b-5958-47ff-a1e7-4f23d99583ba    NaN    NaN    NaN     NaN   \n",
       "26682  c1f6b555-2eb1-4231-98f6-50a963976431    NaN    NaN    NaN     NaN   \n",
       "26683  c1f7889a-9ea9-4acb-b64c-b737c929599a  570.0  393.0  261.0   345.0   \n",
       "\n",
       "       Target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "26679       1  \n",
       "26680       1  \n",
       "26681       0  \n",
       "26682       0  \n",
       "26683       1  \n",
       "\n",
       "[26684 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####\n",
    "\n",
    "df1 = pd.read_csv(r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\updated_train_lebel.csv')\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readng the diacom files and converting them into jpeg images and copying to another folder according to class lebels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 2/26684 [00:00<22:28, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\rsna-pneumonia-detection-challenge\\stage_2_train_images is 26684\n",
      "[0, 1]\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 26684/26684 [07:42<00:00, 57.73it/s]\n",
      "  0%|                                                                                        | 0/26684 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 26684/26684 [02:13<00:00, 199.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import pydicom as dicom\n",
    "import matplotlib.pylab as plt\n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "\n",
    "## source images path\n",
    "img_dir = r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\rsna-pneumonia-detection-challenge\\stage_2_train_images'\n",
    "images_list = os.listdir(img_dir)\n",
    "print(\"Number of files in \" + img_dir + \" is \" + str(len(images_list)))\n",
    "#print(images)\n",
    "\n",
    "# destination path \n",
    "training_path = r'F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset'\n",
    "\n",
    "\n",
    "## loops over unique lebels to sort the ids of each unique class\n",
    "label = list(df1['Target'].unique())\n",
    "print (label)\n",
    "\n",
    "image_names = []\n",
    "for catagories in label :\n",
    "     \n",
    "    print(catagories) # each unique class\n",
    "    \n",
    "    #making paths in the target directory \n",
    "    target_dir_make = os.makedirs(os.path.join( training_path , str(catagories) ))\n",
    "    target_dir = os.path.join( training_path , str(catagories) )\n",
    "    \n",
    "    #checks the patient ids from the unique class lebels and stores in a list\n",
    "    class_lebel_x = df1.loc[df1['Target'] == catagories]\n",
    "    names_x = class_lebel_x.patientId\n",
    "    names_x = names_x + \".dcm\"\n",
    "    names_xx = names_x.to_list()\n",
    "    #print(names_xx)\n",
    "    \n",
    "    ## converting the diacom files into jpg files and sorting them according to their class lebels\n",
    "    for dirname, dirnames, filenames in os.walk(img_dir):\n",
    "        for filename in tqdm(filenames):\n",
    "            # checks which id names from the images form the source is equal to the dedicated class lebel\n",
    "            for i in names_xx :\n",
    "                if filename == i :\n",
    "                    # if found similar then converts to jpg format and stores in a dedicated class folder\n",
    "                    image_path = os.path.join( img_dir , filename)\n",
    "                    target_path = os.path.join( target_dir , filename)###\n",
    "                    ds = dicom.dcmread(image_path)\n",
    "\n",
    "                    pixel_array_numpy = ds.pixel_array\n",
    "\n",
    "                    image_format = '.jpg' # or '.png'\n",
    "                    image = target_path.replace('.dcm', image_format)\n",
    "\n",
    "                    cv2.imwrite( image , pixel_array_numpy)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making : training> unique class folders and similarly validation > unique class folders || and moving the images to those respectve folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "0\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\0\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\train\\0\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\val\\0\n",
      "20672\n",
      "16537\n",
      "4134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 1/2 [04:42<04:42, 282.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\1\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\train\\1\n",
      "F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\val\\1\n",
      "26684\n",
      "21347\n",
      "5336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [06:10<00:00, 185.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil\n",
    "\n",
    "\n",
    "label = list(df1['Target'].unique())\n",
    "print (label) \n",
    "\n",
    "\n",
    "dataset_path = r\"F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\"\n",
    "training_path = r\"F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\train\"\n",
    "validation_path = r\"F:\\pneumonia\\000 P R O J E C T S\\pneumonia\\New folder\\dataset\\val\"\n",
    "\n",
    "image_names = []\n",
    "for catagories in tqdm(label) :\n",
    "     \n",
    "    print(catagories)\n",
    "\n",
    "    dataset_dir = os.path.join( dataset_path , str(catagories))\n",
    "    \n",
    "    ## making directories of unique lebels (classes) \n",
    "    # if folder created then works only once. needs to be deleted to reuse\n",
    "    training_dir_make = os.makedirs(os.path.join( training_path , str(catagories) ) )\n",
    "    val_dir_make = os.makedirs(os.path.join( validation_path , str(catagories) ) )\n",
    "    \n",
    "    ## training and validation directories\n",
    "    training_dir = os.path.join( training_path , str(catagories) )\n",
    "    val_dir = os.path.join( validation_path , str(catagories) )\n",
    "    \n",
    "    print(dataset_dir)\n",
    "    print(training_dir)\n",
    "    print(val_dir)\n",
    "       \n",
    "    for dirname, dirnames, filenames in os.walk(dataset_dir):\n",
    "        for filename in filenames:\n",
    "            image_names.append(filename)\n",
    "    \n",
    "    image_names.sort()\n",
    "    random.shuffle(image_names)\n",
    "    split_1 = int(0.8 * len(image_names)) #train\n",
    "    split_2 = int(0.2 * len(image_names)) #validation\n",
    "            \n",
    "    print(len(image_names))\n",
    "    print((split_1))\n",
    "    print((split_2))\n",
    "              \n",
    "    train_filenames = image_names[:split_1]\n",
    "    val_filenames = image_names[:split_2]\n",
    "    \n",
    "    for dirname, dirnames, filenames in os.walk(dataset_dir):\n",
    "        for filename in filenames:\n",
    "            if filename in train_filenames:\n",
    "                shutil.copyfile( os.path.join( dataset_dir , filename)   , os.path.join(training_dir , filename))\n",
    "            if filename in val_filenames:\n",
    "                shutil.copyfile( os.path.join( dataset_dir , filename)   , os.path.join(val_dir , filename))\n",
    "                \n",
    "    \n",
    "    \n",
    "print (label)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
